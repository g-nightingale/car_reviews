{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM500329: Car Reviews Assignment\n",
    "#### Objectives\n",
    "The objectives of this assignment are as follows:\n",
    "\n",
    "***Part 1: Sentiment prediction using naive Bayes***\n",
    "- Implement a naive Bayes classifier using 80% (1106) of the reviews as training data. The training data should be selected at random from the full dataset. \n",
    "- Test the classifier using the remaining 20% (276) of the reviews and report the classifier’s performance using a confusion matrix.\n",
    "\n",
    "***Part 2: Creating an improved classifier***\n",
    "- Identify and research a way to improve on the solution to part 1.\n",
    "- Implement this improvement and compare the results to the initial naive Bayes classifier.\n",
    "\n",
    "#### Contents\n",
    "<a href='#part1'>1. Sentiment prediction using naive Bayes</a>  \n",
    "<a href='#part1.1'>- 1.1 Import data</a>  \n",
    "<a href='#part1.2'>- 1.2 Clean text data</a>   \n",
    "<a href='#part1.3'>- 1.3 Split data into training and test sets</a>  \n",
    "<a href='#part1.4'>- 1.4 Apply stemming to the data</a>  \n",
    "<a href='#part1.5'>- 1.5 Transform the training and test data using a bag of words model</a>   \n",
    "<a href='#part1.6'>- 1.6 Train a multinomial naive Bayes model and assess performance</a>  \n",
    "\n",
    "<a href='#part2'>2. Creating an improved classifier</a>  \n",
    "<a href='#part2.1'>- 2.1 Reassess performance of baseline model</a>  \n",
    "<a href='#part2.2'>- 2.2 Improving baseline performance</a>  \n",
    "<a href='#part2.3'>- 2.3 Document vectors</a>   \n",
    "<a href='#part3'>3. Conclusions</a>  \n",
    "<a href='#part4'>4. References</a>\n",
    "\n",
    "#### Notes\n",
    "- To keep the notebook as clean as possible I have saved user defined functions and classes in a separate file named car_reviews_utils.py. These functions are presented in the same order that they appear within the notebook.\n",
    "- Throughout this notebook, summaries of key findings for each section are written in <font color=blue> **blue text** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "file_name = 'car-reviews.csv'\n",
    "test_size = 0.2\n",
    "\n",
    "%run \"car_reviews_utils.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sentiment prediction using naive Bayes <a id='part1'></a>\n",
    "\n",
    "In this section we will clean the data, build a Naive Bayes model to predict sentiment and evaluate performance.\n",
    "\n",
    "#### contents  \n",
    "<a href='#part1.1'>1.1 Import data</a>  \n",
    "<a href='#part1.2'>1.2 Clean text data</a>   \n",
    "<a href='#part1.3'>1.3 Split data into training and test sets</a>  \n",
    "<a href='#part1.4'>1.4 Apply stemming to the data</a>  \n",
    "<a href='#part1.5'>1.5 Transform the training and test data using a bag of words</a>   \n",
    "<a href='#part1.6'>1.6 Train a Multinomial Naive Bayes Model and assess performance</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import data <a id='part1.1'></a>\n",
    "Firstly, let's import our data using Pandas and do some high level checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1382 entries, 0 to 1381\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentiment  1382 non-null   object\n",
      " 1   Review     1382 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 21.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "car_reviews = pd.read_csv(file_name)\n",
    "car_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neg</td>\n",
       "      <td>In 1992 we bought a new Taurus and we really loved it  So in 1999 we decided to try a new Tauru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neg</td>\n",
       "      <td>The last business trip  I drove to San Francisco  I went to Hertz Rentals and got a 1999 Ford T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neg</td>\n",
       "      <td>My husband and I purchased a 1990 Ford F250 and had nothing but problems  we have owned the veh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neg</td>\n",
       "      <td>I feel I have a thorough opinion of this truck compared to most who post evaluations of their v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neg</td>\n",
       "      <td>AS a mother of 3  all of whom are still in carseats  the only logical thing to do was to trade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  \\\n",
       "0       Neg   \n",
       "1       Neg   \n",
       "2       Neg   \n",
       "3       Neg   \n",
       "4       Neg   \n",
       "\n",
       "                                                                                                Review  \n",
       "0   In 1992 we bought a new Taurus and we really loved it  So in 1999 we decided to try a new Tauru...  \n",
       "1   The last business trip  I drove to San Francisco  I went to Hertz Rentals and got a 1999 Ford T...  \n",
       "2   My husband and I purchased a 1990 Ford F250 and had nothing but problems  we have owned the veh...  \n",
       "3   I feel I have a thorough opinion of this truck compared to most who post evaluations of their v...  \n",
       "4   AS a mother of 3  all of whom are still in carseats  the only logical thing to do was to trade ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few records of the data\n",
    "car_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pos    691\n",
       "Neg    691\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sentiment counts\n",
    "car_reviews['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    691\n",
       "1    691\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the sentiment field with a binary flag\n",
    "replace_dict = {'Neg':0, 'Pos':1}\n",
    "car_reviews.replace({'Sentiment':replace_dict}, inplace=True)\n",
    "car_reviews['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- The data has 1,382 records\n",
    "- We have converted sentiment to a binary variable, where a value of 1 represents a positive review. This is in preparation for the supervised machine learning algorithms that we will apply later on\n",
    "- Sentiment is evenly balanced, we have 691 positive reviews and 691 negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clean text data <a id='part1.2'></a>\n",
    "As a next step, let's clean the review variable so that it's in good shape for creating a bag of words model. We can do this step on all the data at once, without having to worry about data leakage between training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bought new taurus really loved decided try new taurus care style newer version bought like new c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>business trip drove san francisco went hertz rentals got ford taurus thinking looked comfortable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>husband purchased ford f problems owned vehicle approximately years spent half time shop problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>feel thorough opinion truck compared post evaluations vehicles truck owned new currently k miles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mother carseats logical thing trade sx minivan minivan handful vehicles room family requires add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                Review  \n",
       "0  bought new taurus really loved decided try new taurus care style newer version bought like new c...  \n",
       "1  business trip drove san francisco went hertz rentals got ford taurus thinking looked comfortable...  \n",
       "2  husband purchased ford f problems owned vehicle approximately years spent half time shop problem...  \n",
       "3  feel thorough opinion truck compared post evaluations vehicles truck owned new currently k miles...  \n",
       "4  mother carseats logical thing trade sx minivan minivan handful vehicles room family requires add...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the nltk and scikit-learn stopword lists!\n",
    "all_stop_words = set(stopwords.words('english')).union(set(ENGLISH_STOP_WORDS))\n",
    "\n",
    "# Clean the data\n",
    "car_reviews_clean = clean_text_data(car_reviews, 'Review', all_stop_words)\n",
    "car_reviews_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 before cleaning:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' In 1992 we bought a new Taurus and we really loved it  So in 1999 we decided to try a new Taurus  I did not care for the style of the newer version  but bought it anyway I do not like the new car half as much as i liked our other one  Thee dash is much to deep and takes up a lot of room  I do not find the seats as comfortable and the way the sides stick out further than the strip that should protect your card from denting It drives nice and has good pick up  But you can not see the hood at all from the driver seat and judging and parking is difficult  It has a very small gas tank I would not buy a Taurus if I had it to do over  I would rather have my 1992 back  I dont think the style is as nice as the the 1992  and it was a mistake to change the style  In less than a month we had a dead battery and a flat tire '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bought new taurus really loved decided try new taurus care style newer version bought like new car half liked thee dash deep takes lot room seats comfortable way sides stick strip protect card denting drives nice good pick hood driver seat judging parking difficult small gas tank buy taurus dont think style nice mistake change style month dead battery flat tire'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print original and cleaned review\n",
    "idx = 0\n",
    "print(f'Review {idx} before cleaning:')\n",
    "display(car_reviews['Review'][idx])\n",
    "\n",
    "print(f'Review {idx} after cleaning:')\n",
    "display(car_reviews_clean['Review'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- Our data has been cleaned!   \n",
    "    - non-alphabetical characters have been removed\n",
    "    - stop words such as 'in', 'we' and 'a' which are unlikely to affect sentiment have been removed\n",
    "    - uppercase characters have been converted to lowercase\n",
    "    - leading/trailing and multiple spaces have been removed\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split data into training and test sets <a id='part1.3'></a>\n",
    "Next we will split the data into a training set with 80% of the data and a set set with the remaining 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets convert the DataFrame to lists for the x and y variables\n",
    "car_reviews_list = car_reviews_clean.values.tolist()\n",
    "\n",
    "x = [x[1] for x in car_reviews_list]\n",
    "y = [x[0] for x in car_reviews_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of data to use for training 80.0%\n",
      "training set observations: 1105\n",
      "training set positive reviews: 554 \n",
      "\n",
      "% of data to use for testing 20.0%\n",
      "test set observations: 277\n",
      "test set positive reviews: 137\n"
     ]
    }
   ],
   "source": [
    "# Use train_test_split to create training and testing datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=84, shuffle=True)\n",
    "\n",
    "print(f'% of data to use for training {(1-test_size)*100}%')\n",
    "print(f'training set observations: {len(x_train)}')\n",
    "print(f'training set positive reviews: {sum(y_train)} \\n')\n",
    "print(f'% of data to use for testing {test_size*100}%')\n",
    "print(f'test set observations: {len(x_test)}')\n",
    "print(f'test set positive reviews: {sum(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    " - The data has been split into a training set with 80% of the data and a test set with 20% of the data\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Apply stemming to the data <a id='part1.4'></a>\n",
    "In this section we will apply stemming to the data.\n",
    "\n",
    "According to Wikipedia, 'stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form—generally a written word form'.\n",
    "\n",
    "Stemming reduces variations of a word to a common root form. For example 'walk', 'walked' and 'walking' would all be stemmed to 'walk'. Using stemming we group together similar words that have a shared root form, and presumably shared meanings. Stemming will help to reduce the number of dimensions in our bag of words model. \n",
    "\n",
    "In this assignment we will use the NLTK implementation of the English (Porter2) stemmer. This stemmer makes several improvements to the original Porter stemmer introduced by M.F. Porter in 1980, generally through modified treatment of various suffixes (Snowballstem, 2002).\n",
    "\n",
    "Concrete examples of stemming will be given in the following cells.\n",
    "\n",
    "**Note:** In part 2 of this assignment we will explore lemmatization as an alternative to stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size before stemming: 14328\n",
      "vocabulary size after stemming: 9033\n"
     ]
    }
   ],
   "source": [
    "# How does stemming impact the size of our vocabulary?\n",
    "x_train_stem = stem_docs(x_train)\n",
    "x_test_stem = stem_docs(x_test)\n",
    "\n",
    "# Create a CountVectorizer and extract the vocab\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train)\n",
    "vectorizer_vocab = vectorizer.get_feature_names()\n",
    "\n",
    "# Create a CountVectorizer with stemming and extract the vocab\n",
    "vectorizer_stem = CountVectorizer()\n",
    "vectorizer_stem.fit(x_train_stem)\n",
    "vectorizer_stem_vocab = vectorizer_stem.get_feature_names()\n",
    "\n",
    "print(f'vocabulary size before stemming: {len(vectorizer_vocab)}')\n",
    "print(f'vocabulary size after stemming: {len(vectorizer_stem_vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse the impact of stemming on a few words in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming example for words starting with \"acceler\"\n",
      "Original vocabulary\n",
      "['accelerate', 'accelerated', 'accelerates', 'accelerating', 'acceleration', 'accelerations', 'accelerator']\n",
      "Stemmed vocabulary\n",
      "['acceler'] \n",
      "\n",
      "Stemming example for words starting with \"impress\"\n",
      "Original vocabulary\n",
      "['impress', 'impressed', 'impresses', 'impressing', 'impression', 'impressions', 'impressive', 'impressively']\n",
      "Stemmed vocabulary\n",
      "['impress'] \n",
      "\n",
      "Stemming example for words starting with \"transmis\"\n",
      "Original vocabulary\n",
      "['transmissiion', 'transmission', 'transmissions']\n",
      "Stemmed vocabulary\n",
      "['transmiss', 'transmissiion'] \n",
      "\n",
      "Stemming example for words starting with \"qualit\"\n",
      "Original vocabulary\n",
      "['qualities', 'quality']\n",
      "Stemmed vocabulary\n",
      "['qualiti'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check a few examples before and after stemming\n",
    "before_and_after_stemming('acceler', vectorizer_vocab, vectorizer_stem_vocab)\n",
    "before_and_after_stemming('impress', vectorizer_vocab, vectorizer_stem_vocab)\n",
    "before_and_after_stemming('transmis', vectorizer_vocab, vectorizer_stem_vocab)\n",
    "before_and_after_stemming('qualit', vectorizer_vocab, vectorizer_stem_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- Words like 'accelerate', 'accelerated' and 'accelerates' are stemmed to the common root of 'accel'\n",
    "- Applying stemming reduces the number of words in our vocabulary from **14,328** to **9,033**\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Transform the training and test data using a bag of words model <a id='part1.5'></a>\n",
    "\n",
    "We will now transform the documents into numerical feature vectors using a bag of words model.\n",
    "\n",
    "#### Bag of words model\n",
    "Bag of words models are one of the most common ways of converting text data into numerical features. A separate feature is output for every unique word in of the all documents, and the value of each feature for a given document represents the number of times that the word appears in within that document (Albon, 2018).\n",
    "\n",
    "We will use the Scikit-Learn CountVectorizer class to create our bag of words model.\n",
    "\n",
    "**Note:** The count vectors are fit using only the documents from our training data, so as to prevent any data leakage arising from 'seeing' words from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training matrix shape (1105, 9033)\n",
      "test matrix shape (277, 9033)\n"
     ]
    }
   ],
   "source": [
    "# Transform the review data using the count vectorizer\n",
    "x_train_vec = vectorizer_stem.transform(x_train_stem).toarray()\n",
    "x_test_vec = vectorizer_stem.transform(x_test_stem).toarray()\n",
    "\n",
    "print(f'training matrix shape {x_train_vec.shape}')\n",
    "print(f'test matrix shape {x_test_vec.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking word fequencies\n",
    "\n",
    "Let's have a look at the top 10 words by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot word frequencies\n",
    "plot_word_freq(x_train_vec, vectorizer_stem.get_feature_names(), n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the frequency plot we see that 'car' is the most common word, appearing almost 6,000 times across documents in the training set. 'ford' is the second most common word, appearing almost 3,000 times. The fact that 'ford' appears so often is quite interesting, especially given the absence of other card brands amongst frequent words. Perhaps our review data is exclusively for Ford vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the vectors\n",
    "\n",
    "Observing the first 5 vectors from the training data we can see that the data appears to be sparsely populated, there are lots of zeros ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 3, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vec[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check which indices in the vector are non-zero using numpy's nonzero function. Let's check the first vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  30,   83,   93,  135,  146,  149,  167,  212,  213,  239,  309,\n",
       "         321,  363,  381,  495,  499,  525,  565,  621,  666,  685,  689,\n",
       "         717,  800,  833,  839,  863,  868,  913,  953,  968, 1008, 1021,\n",
       "        1053, 1091, 1103, 1115, 1168, 1246, 1247, 1272, 1347, 1362, 1397,\n",
       "        1417, 1442, 1460, 1471, 1479, 1499, 1530, 1620, 1634, 1669, 1670,\n",
       "        1704, 1777, 1801, 1838, 1848, 1861, 1870, 1887, 1907, 1910, 1936,\n",
       "        1942, 1946, 2004, 2116, 2242, 2308, 2357, 2379, 2389, 2399, 2402,\n",
       "        2442, 2443, 2459, 2520, 2532, 2538, 2555, 2600, 2654, 2673, 2681,\n",
       "        2686, 2691, 2720, 2727, 2741, 2749, 2768, 2780, 2783, 2804, 2812,\n",
       "        2815, 2861, 2865, 2922, 2927, 2972, 2973, 2997, 3029, 3038, 3062,\n",
       "        3075, 3121, 3175, 3191, 3222, 3290, 3306, 3309, 3314, 3323, 3377,\n",
       "        3379, 3397, 3426, 3458, 3485, 3489, 3502, 3522, 3526, 3550, 3566,\n",
       "        3618, 3645, 3676, 3678, 3706, 3729, 3784, 3789, 3822, 3824, 3865,\n",
       "        3911, 3913, 3981, 3998, 4024, 4053, 4075, 4087, 4155, 4186, 4235,\n",
       "        4329, 4376, 4377, 4421, 4448, 4453, 4460, 4472, 4497, 4507, 4514,\n",
       "        4522, 4530, 4536, 4551, 4565, 4591, 4594, 4596, 4608, 4644, 4652,\n",
       "        4675, 4719, 4724, 4730, 4750, 4794, 4827, 4837, 4853, 4962, 4978,\n",
       "        4981, 5020, 5029, 5031, 5114, 5125, 5149, 5165, 5179, 5207, 5209,\n",
       "        5222, 5251, 5312, 5322, 5340, 5341, 5345, 5397, 5453, 5482, 5493,\n",
       "        5504, 5506, 5512, 5551, 5611, 5646, 5660, 5724, 5735, 5745, 5762,\n",
       "        5774, 5790, 5843, 5862, 5926, 5932, 5968, 6042, 6089, 6094, 6113,\n",
       "        6128, 6144, 6167, 6198, 6235, 6240, 6252, 6332, 6346, 6358, 6395,\n",
       "        6400, 6465, 6473, 6505, 6510, 6534, 6555, 6570, 6598, 6625, 6646,\n",
       "        6703, 6741, 6764, 6770, 6780, 6783, 6818, 6851, 6877, 6908, 6911,\n",
       "        6916, 6922, 6930, 6974, 6998, 7035, 7086, 7097, 7101, 7113, 7189,\n",
       "        7193, 7222, 7232, 7245, 7250, 7251, 7265, 7317, 7322, 7336, 7385,\n",
       "        7446, 7458, 7476, 7483, 7496, 7519, 7533, 7535, 7561, 7642, 7662,\n",
       "        7666, 7676, 7700, 7701, 7716, 7746, 7755, 7761, 7767, 7768, 7771,\n",
       "        7797, 7848, 7859, 7915, 7917, 7946, 7947, 7983, 7988, 7997, 8019,\n",
       "        8028, 8058, 8066, 8075, 8090, 8095, 8118, 8126, 8127, 8172, 8185,\n",
       "        8230, 8244, 8314, 8493, 8505, 8515, 8592, 8620, 8678, 8714, 8733,\n",
       "        8748, 8753, 8761, 8775, 8814, 8822, 8830, 8839, 8857, 8860, 8934,\n",
       "        9003], dtype=int64),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(x_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output we can see that index 30, 83, ... , 9003 are non-zero for this vector. The words represented by these indices appear at least once for the first training example. This output is still not very useful because we do not know which words these indices map to, let's check these in the next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceler\n",
      "add\n",
      "yrs\n"
     ]
    }
   ],
   "source": [
    "# Check words from our vocab for indicies 30, 83 and 9003\n",
    "print(vectorizer_stem_vocab[30])\n",
    "print(vectorizer_stem_vocab[83])\n",
    "print(vectorizer_stem_vocab[9003])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- The bag of words model enables us to give our text data a numeric representation\n",
    "- The CountVectorizer converts a collection of documents into a matrix of word counts\n",
    "- The count vectors are generally sparsely populated\n",
    "- Using numpy's nonzero function we can find which indices in a given vector are populated and plug these indices back into our vocabulary in order to verify which words are present for a given training example</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Train a multinomial naive Bayes model and assess performance <a id='part1.6'></a>\n",
    "In this section we will: \n",
    "- Train a multinomial naive Bayes model on the training data using the Scikit-Learn multinomial naive Bayes classifier\n",
    "- Measure performance using accuracy and a confusion matrix\n",
    "- Discuss other performance measures including precision, recall and f1 scores\n",
    "\n",
    "#### Multinomial naive Bayes\n",
    "Multinomial naive Bayes (MNB) implements the naive Bayes model for multinomially distributed data. This algorithm is suitable for discrete data which follow a multinomial distribution, such as the word count vectors for our reviews. In fact, one of the most common uses of multinomial naive Bayes is for text classification (Albon, 2018). Naive Bayes assumes conditional independence amongst the features. This means that a value of a given feature is independent of the value of any other feature, given the class variable:   \n",
    "\n",
    "$ p(x_1, x_2, x_3, ... ,x_n | y) = \\displaystyle \\prod_{i=1}^{n} p(x_i|y) $  \n",
    "\n",
    "\n",
    "In this assignment we will use the Scikit-Learn implementation of multinomial naive Bayes.  \n",
    "\n",
    "***A note on accuracy as a performance metric:***  \n",
    "\n",
    "Because the sentiment class is balanced, accuracy is an appropriate performance metric for this problem. \n",
    "\n",
    "If sentiment were extremely skewed - say 1 in 100 reviews were positive, accuracy would not be a good metric as our classifier could achieve 99% accuracy by always predicting a negative review, which would not be very useful.\n",
    "\n",
    "Metrics such as precision and recall should be considered when our classes are extremely unbalanced or the costs associated with type 1 and type 2 errors are asymmetric. These metrics will be discussed briefly at the end of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy 0.9149\n",
      "test set accuracy 0.7617\n"
     ]
    }
   ],
   "source": [
    "# Train the model and print accuracy\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_vec, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(x_train_vec)\n",
    "y_test_pred = clf.predict(x_test_vec)\n",
    "\n",
    "print_accuracy(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier achieves 76.17% accuracy on the test set - which seems pretty good, definitely much better than random!\n",
    "\n",
    "But how would a human would perform on such a task? It seems reasonable that a human could perform this task very easily and achieve accuracy close to 100%. Perhaps our classifier isn't very good after all.\n",
    "\n",
    "Let's examine the confusion matrix to better understand where our errors are coming from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set confusion matrix (proportion):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted:0</th>\n",
       "      <th>Predicted:1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual:0</th>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.4986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual:1</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.5014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.5104</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted:0  Predicted:1   Total\n",
       "Actual:0       0.4516       0.0471  0.4986\n",
       "Actual:1       0.0380       0.4633  0.5014\n",
       "Total          0.4896       0.5104  1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test set confusion matrix (proportion):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted:0</th>\n",
       "      <th>Predicted:1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual:0</th>\n",
       "      <td>0.3827</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>0.5054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual:1</th>\n",
       "      <td>0.1155</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted:0  Predicted:1   Total\n",
       "Actual:0       0.3827       0.1227  0.5054\n",
       "Actual:1       0.1155       0.3791  0.4946\n",
       "Total          0.4982       0.5018  1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print confusion matrices\n",
    "train_cm_prop = labelled_confusion_matrix(y_train, y_train_pred, prop=True) \n",
    "test_cm_prop = labelled_confusion_matrix(y_test, y_test_pred, prop=True) \n",
    "\n",
    "print('\\ntraining set confusion matrix (proportion):')\n",
    "display(train_cm_prop)\n",
    "\n",
    "print('\\ntest set confusion matrix (proportion):')\n",
    "display(test_cm_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ***test set*** confusion matrix we can observe the following:\n",
    "- 37.91% of predictions are true positives\n",
    "- 38.27%  of predictions are true negatives\n",
    "- 12.27% of predictions are false positives\n",
    "- 11.55% of predictions are false negatives\n",
    "\n",
    "We are seeing slightly more errors from falsely predicting the positive class verses falsely predicting the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall & F1 scores\n",
    "\n",
    "In practice it's also common to measure the precision, recall and f1 scores when analysing the performance of a binary classifier, especially when the classes are skewed or the costs of type 1 and type 2 errors are asymmetric.\n",
    "- Precision tells us what proportion of our predictions for the positive class are correct\n",
    "- Recall tells us what proportion of the total positive class our classifier captures\n",
    "- The f1 score is the harmonic mean of precision and recall, and can be used as a single metric to compare models\n",
    "\n",
    "These metrics are calculated as follows:\n",
    "- $precision \\ = \\ tp \\ / \\ (tp \\ + \\ fp)$ \n",
    "- $recall \\ = \\ tp \\ / \\ (tp \\ + \\ fn)$\n",
    "- $f_1\\ = \\ 2 \\times (precision \\ \\times \\ recall) \\ / \\ (precision \\ + \\ recall)$\n",
    "\n",
    "\n",
    "Let's calculate the precision, recall and f1 score for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set performance:\n",
      "training precision score: 0.9078\n",
      "training recall score: 0.9242\n",
      "training f1 score: 0.9159\n",
      "\n",
      "test set performance:\n",
      "testing precision score: 0.7554\n",
      "testing recall score: 0.7664\n",
      "testing f1 score: 0.7609\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall and f1 metrics\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the test set results we can observe:\n",
    "- Our classifier has a precision of 75.54%. This means that our classifier was correct 75.54% of the time when it predicted positive reviews\n",
    "- Our classifier has a recall score of 76.64%. This means that our classifier captures 76.64% of all positive reviews when it predicted positive reviews\n",
    "- Our classifier achieves an f1 score of 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- Our classifier correctly predicts 76.17% of observations on our test set\n",
    "    - Accuracy is a good performance metric for this problem, because our classes are balanced\n",
    "    - The performance of our classifier is far from human level\n",
    "- By producing a confusion matrix, we can make the following observations about the errors:\n",
    "    - 12.27% of predictions are false positives\n",
    "    - 11.55% of predictions are false negatives\n",
    "- We have briefly covered precision, recall and f1 scores </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Creating an improved classifier <a id='part2'></a>\n",
    "In this section we will look at ways to improve our classifier.\n",
    "\n",
    "#### Contents\n",
    "<a href='#part2.1'>2.1 Reassess performance of baseline model</a>  \n",
    "<a href='#part2.2'>2.2 Improving baseline performance</a>  \n",
    "<a href='#part2.3'>2.3 Document vectors</a>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reassess performance of baseline model <a id='part2.1'></a>\n",
    "\n",
    "#### Establishing baseline performance\n",
    "In part 1 our classifier achieved an accuracy of 76.17% of the test set.\n",
    "\n",
    "However what if we sampled our test set slightly differently?\n",
    "\n",
    "By changing the random number seed in the *train_test_split* function to 42 and running the remaining code without change, we would now get an accuracy of 81.59% on the test set.\n",
    "\n",
    "That's more than an 7% improvement in performance!\n",
    "\n",
    "How do we know which results to trust? \n",
    "\n",
    "What we really want to know is how our classifier will generalise on unseen data, and using a single test set for this purpose isn't great because results can be driven by natural variation associated with the sampling process. When using a single test dataset our generalization error is less reliable and we cannot compute variance or confidence intervals around our estimate (Zheng, 2015). \n",
    "\n",
    "From the Law of Large numbers we know that as we increase the number of trials for an experiment our estimate for the mean will converge towards the true population mean.\n",
    "\n",
    "Enter Monte Carlo Cross Validation...\n",
    "\n",
    "#### Monte Carlo Cross Validation\n",
    "Monte Carlo Cross Validation (also known as repeated random sub-sample validation or simply bootstrapping) is a technique used to assess how a model will generalise to an independent set of data.\n",
    "\n",
    "In each iteration of Monte Carlo Cross Validation we randomly shuffle our data, select a proportion of the data for training and use the remaining data for validation. \n",
    "\n",
    "The training set is used to train a model and the validation set is used to create predictions and measure performance, using a metric such as accuracy. \n",
    "\n",
    "We repeat this process many times and calculate the average scores across all iterations to obtain the expected performance for the classifier (Zheng, 2015).\n",
    "\n",
    "\n",
    "We will apply Monte Carlo Cross Validation to the model from part 1 to calculate the mean accuracy using the following settings:\n",
    "- Number of iterations: 30\n",
    "- Training set %: 70.0\n",
    "- Validation set %: 30.0\n",
    "\n",
    "We have chosen 30 iterations as a sample size of 30 is generally considered the minimum number of samples required to approximate a normal distribution for a random variable.\n",
    "\n",
    "**We will still use our test set to report the final results of our model, however we will use cross validation to understand the expectation and variance of a model and also to compare candidate models. Test set results will not be used to decide which model to use.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orangered'> **Implementation note:**  \n",
    "My implementation of Monte Carlo Cross Validation takes random sub-samples from the original training set to create the cv training and validation sets.\n",
    "\n",
    "A function called feature_vectorisation is passed into the MonteCarloCV train_params() method and handles pre-processing steps such as stemming and the creation of count vectors. This function also ensures that pre-processing steps such as creating count vectors are trained only the cv training set and then applied to the cv validation set in order to prevent any data leakage. See car_reviews_utils.py for further details.\n",
    "    \n",
    "In the interests of time, cross validation results have been hardedcoded in the remainder of this notebook, as cross validation can take several minutes to run. If a user wishes to reproduce the cross validation results for themselves they can do so by setting run_mccv to True.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MNB model through Monte Carlo Cross Validation\n",
    "run_mccv = False\n",
    "\n",
    "if run_mccv:\n",
    "    models = [MultinomialNB()]\n",
    "    params = [{'stem':True, 'count_vectorizer':True, 'min_df':1, 'ngram_range':(1, 1)}]\n",
    "\n",
    "    mccv = MonteCarloCV(models, number_of_runs=30)\n",
    "    mccv.train_params(x_train, y_train, feature_processing=feature_vectorisation, params=params,\n",
    "                      verbose=True, verbose_n=10)\n",
    "\n",
    "    model_labels = ['MNB - Baseline']\n",
    "    mccv.plot_scores(labels=model_labels, xlim=(0.7, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='mccv1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- From the results of Monte Carlo Cross Validation we find that:\n",
    "    - Our classifer achieves a mean accuracy of 76.8% with a standard deviation of 2.26%\n",
    "    - This aligns with our test set result of 76.17%\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Improving baseline performance <a id='part2.2'></a>\n",
    "In this section we will try and improve on our baseline model.\n",
    "\n",
    "Wang and Manning (2012) find that support vector machines (SVMs) and bigrams generate superior results for sentiment analysis tasks when compared with naive Bayes and unigrams, especially for long documents such as full length reviews.\n",
    "\n",
    "In addition to trialling SVMs and bigrams, we will also explore the use of:\n",
    "- Lemmatization in document pre-processing\n",
    "- TF-IDF weighting\n",
    "- Trigrams\n",
    "\n",
    "We will trial several model configurations and compare cross validation results.\n",
    "\n",
    "Let's briefly cover support vector machines, n-gram ranges, lemmatization, and TF-IDF weighting as we have not yet discussed these concepts.\n",
    "\n",
    "#### Support Vector Machines\n",
    "As found by Wang and Manning (2012), the support vector machine algorithm can deliver superior performance to multinomial naive Bayes for text classification tasks.\n",
    "\n",
    "Support vector machines (SVM) construct hyperplanes in high dimensional space, with the goal of maximizing the distance between the hyperplane and the class members in order to minimize classification error. Because they use hyperplanes to determine class membership, support vector machines do not output probability estimates, unlike most classification algorithms (Albon, 2018). Support vector machines are known to be very effective in scenarios where the data is highly dimensional and when the number of dimensions is greater than the number of samples (Geron, 2017). Both of these cases are true for our car review data.\n",
    "\n",
    "Typically SVMs require the input data to be standardised, however as all of our data is measured in the same units or normalised via TF-IDF, this step is not necessary.\n",
    "\n",
    "We will use the Scikit-Learn implementation of SVMs via the LinearSVC class.\n",
    "\n",
    "#### N-gram range\n",
    "In our baseline model we have only considered single words, also known as unigrams. We will also trial the use of bigrams (two consecutive words) and trigrams (three consecutive words). Below are some examples of unigrams, bigrams and trigrams:\n",
    "\n",
    "- Unigrams: 'accelerate', 'overhead', 'test'\n",
    "- Bigrams: 'accelerate easily',  'overhead cam', 'test drive'  \n",
    "- Trigrams: 'accelerate cruising speed', 'overhead cam engine', 'test drive surprised'\n",
    "\n",
    "#### Lemmatization\n",
    "Lemmatization serves a similar function to stemming, in the sense that both methods look to reduce inflected forms of words to a common base. However unlike stemming, lemmatizers have knowledge of word context, and are able to discriminate between words that have differing meanings depending on part of speech. \n",
    "\n",
    "For example, 'better' has 'good' as its lemma, and both would be transformed to 'good' using a lemmatizer. Using stemming both words would be unchanged.\n",
    "\n",
    "Lemmatization relies on a lexical knowledge base such as WordNet base to obtain the correct base form of words. One disadvantage of lemmatization is that it is computationally expensive as it needs to consult the lexical knowledge base as well as understand part of speech. In scenarios where speed is paramount, stemming may be preferred.\n",
    "\n",
    "In this assignment we will use the WordNet implementation of lemmatization from the NLTK library.\n",
    "\n",
    "#### TF-IDF weighting\n",
    "Term frequency inverse document frequency (TF-IDF) is a method of weighting words in a document by the number of times a word appears in a document proportional to the number of documents that contain the word. Words which appear more often in a document, but are less common across all documents are considered to be more informative and are thus given a higher weighting. Conversely, Words which appear less frequently in a document and are common across many documents are given a lower weighting.\n",
    "\n",
    "In this assignment we will use the Scikit-Learn TfidfVectorizer, which first generates a count vectorizer, and then normalises the output using TF-IDF weights. \n",
    "\n",
    "**Before running our models, let's take a look at the frequencies of bigrams and trigrams:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create vectorizers using bigrams and trigrams\n",
    "x_train_stem = stem_docs(x_train)\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(2, 2), max_features=100)\n",
    "vectorizer_bigram.fit(x_train_stem)\n",
    "x_train_bigram = vectorizer_bigram.transform(x_train_stem).toarray()\n",
    "\n",
    "vectorizer_trigram = CountVectorizer(ngram_range=(3, 3), max_features=100)\n",
    "vectorizer_trigram.fit(x_train_stem)\n",
    "x_train_trigram = vectorizer_trigram.transform(x_train_stem).toarray()\n",
    "\n",
    "# Plot bigram and trigram frequencies\n",
    "plot_word_freq(x_train_bigram, vectorizer_bigram.get_feature_names(), n_words=10, \n",
    "               title='Bigram Frequency', color='lightgreen')\n",
    "plot_word_freq(x_train_trigram, vectorizer_trigram.get_feature_names(), n_words=10, \n",
    "               title='Trigram Frequency', color='paleturquoise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For bigrams 'gas mileag', 'wheel drive' and 'ford taurus' are the top 3 most frequent terms.\n",
    "For trigrams 'good gas mileag', 'anti lock brake' and 'rear wheel drive' are the top 3 most frequent terms.\n",
    "\n",
    "Both bigrams and trigrams are much less frequent than what we have seen for unigrams.\n",
    "\n",
    "Interestingly, the term 'ford' appears multiple times across the most frequent bigrams and trigrams, which reinforces our earlier hypothesis that the car reviews in our data may be for Ford motorcars exclusively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing model configurations\n",
    "To find which combinations perform the best we will test a total of 32 model configurations using MNB and SVM algorithms and Monte Carlo cv.\n",
    "\n",
    "For configurations that use a mix of unigrams, bigrams and trigrams we enforce the minimum document frequency to be at least two in order to limit dimensionality.\n",
    "\n",
    "The specific model configurations we will test are:\n",
    "\n",
    "| Config. |Algorithm | Stemming/Lemmatization | Bag of words method | N-gram range | Min document frequency \n",
    "| :--- | :--- | :--- | :--- | :---: | :---: \n",
    "|1|MNB|Stemming|CountVectorizer|(1, 1)|1\n",
    "|2|MNB|Lemmatization|CountVectorizer|(1, 1)|1\n",
    "|3|MNB|Stemming|CountVectorizer|(1, 2)|2\n",
    "|4|MNB|Lemmatization|CountVectorizer|(1, 2)|2\n",
    "|5|MNB|Stemming|CountVectorizer|(1, 3)|2\n",
    "|6|MNB|Lemmatization|CountVectorizer|(1, 3)|2\n",
    "|7|MNB|Stemming|CountVectorizer|(2, 3)|1\n",
    "|8|MNB|Lemmatization|CountVectorizer|(2, 3)|1\n",
    "|9|MNB|Stemming|TfidfVectorizer|(1, 1)|1\n",
    "|10|MNB|Lemmatization|TfidfVectorizer|(1, 1)|1\n",
    "|11|MNB|Stemming|TfidfVectorizer|(1, 2)|2\n",
    "|12|MNB|Lemmatization|TfidfVectorizer|(1, 2)|2\n",
    "|13|MNB|Stemming|TfidfVectorizer|(1, 3)|2\n",
    "|14|MNB|Lemmatization|TfidfVectorizer|(1, 3)|2\n",
    "|15|MNB|Stemming|TfidfVectorizer|(2, 3)|1\n",
    "|16|MNB|Lemmatization|TfidfVectorizer|(2, 3)|1\n",
    "|17|SVM|Stemming|CountVectorizer|(1, 1)|1\n",
    "|18|SVM|Lemmatization|CountVectorizer|(1, 1)|1\n",
    "|19|SVM|Stemming|CountVectorizer|(1, 2)|2\n",
    "|20|SVM|Lemmatization|CountVectorizer|(1, 2)|2\n",
    "|21|SVM|Stemming|CountVectorizer|(1, 3)|2\n",
    "|22|SVM|Lemmatization|CountVectorizer|(1, 3)|2\n",
    "|23|SVM|Stemming|CountVectorizer|(2, 3)|1\n",
    "|24|SVM|Lemmatization|CountVectorizer|(2, 3)|1\n",
    "|25|SVM|Stemming|TfidfVectorizer|(1, 1)|1\n",
    "|26|SVM|Lemmatization|TfidfVectorizer|(1, 1)|1\n",
    "|27|SVM|Stemming|TfidfVectorizer|(1, 2)|2\n",
    "|28|SVM|Lemmatization|TfidfVectorizer|(1, 2)|2\n",
    "|29|SVM|Stemming|TfidfVectorizer|(1, 3)|2\n",
    "|30|SVM|Lemmatization|TfidfVectorizer|(1, 3)|2\n",
    "|31|SVM|Stemming|TfidfVectorizer|(2, 3)|1\n",
    "|32|SVM|Lemmatization|TfidfVectorizer|(2, 3)|1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the parameters - we will trial 16 configurations for both MNB and SVM models\n",
    "params = 2 * [{'stem':True, 'count_vectorizer':True, 'min_df':1, 'ngram_range':(1, 1)},\n",
    "              {'stem':False, 'count_vectorizer':True, 'min_df':1, 'ngram_range':(1, 1)},\n",
    "              {'stem':True, 'count_vectorizer':True, 'min_df':2, 'ngram_range':(1, 2)},\n",
    "              {'stem':False, 'count_vectorizer':True, 'min_df':2, 'ngram_range':(1, 2)},\n",
    "              {'stem':True, 'count_vectorizer':True, 'min_df':2, 'ngram_range':(1, 3)},\n",
    "              {'stem':False, 'count_vectorizer':True, 'min_df':2, 'ngram_range':(1, 3)},\n",
    "              {'stem':True, 'count_vectorizer':True, 'min_df':1, 'ngram_range':(2, 3)},\n",
    "              {'stem':False, 'count_vectorizer':True, 'min_df':1, 'ngram_range':(2, 3)},\n",
    "              {'stem':True, 'count_vectorizer':False, 'min_df':1, 'ngram_range':(1, 1)},\n",
    "              {'stem':False, 'count_vectorizer':False, 'min_df':1, 'ngram_range':(1, 1)},\n",
    "              {'stem':True, 'count_vectorizer':False, 'min_df':2, 'ngram_range':(1, 2)},\n",
    "              {'stem':False, 'count_vectorizer':False, 'min_df':2, 'ngram_range':(1, 2)},\n",
    "              {'stem':True, 'count_vectorizer':False, 'min_df':2, 'ngram_range':(1, 3)},\n",
    "              {'stem':False, 'count_vectorizer':False, 'min_df':2, 'ngram_range':(1, 3)},\n",
    "              {'stem':True, 'count_vectorizer':False, 'min_df':1, 'ngram_range':(2, 3)},\n",
    "              {'stem':False, 'count_vectorizer':False, 'min_df':1, 'ngram_range':(2, 3)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> **Warning! The following cell takes approximately 2 hours to run, therefore run_models is set to false to prevent the following cell from running. The cross validation results produced from running the following cell are hardcoded into the following markdown cell.** </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the models - 16 MNB and 16 SVM\n",
    "run_models = False\n",
    "    \n",
    "if run_models:\n",
    "    models = [MultinomialNB()] * 16 + [LinearSVC()] * 16\n",
    "    mccv = MonteCarloCV(models, number_of_runs=30)\n",
    "    mccv.train_params(x_train, y_train, feature_processing=feature_vectorisation, params=params,\n",
    "                      verbose=False)\n",
    "    \n",
    "    # Creating labels\n",
    "    model_labels = ['MNB', 'SVM']\n",
    "    param_labels = ['stemming, count_vec, ngrams:(1,1)',\n",
    "                    'lemmatize, count_vec, ngrams:(1,1)',\n",
    "                    'stemming, count_vec, ngrams:(1,2)',\n",
    "                    'lemmatize, count_vec, ngrams:(1,2)',\n",
    "                    'stemming, count_vec, ngrams:(1,3)',\n",
    "                    'lemmatize, count_vec, ngrams:(1,3)',\n",
    "                    'stemming, count_vec, ngrams:(2,3)',\n",
    "                    'lemmatize, count_vec, ngrams:(2,3)',\n",
    "                    'stemming, tdif_vec, ngrams:(1,1)',\n",
    "                    'lemmatize, tdif_vec, ngrams:(1,1)',\n",
    "                    'stemming, tdif_vec, ngrams:(1,2)',\n",
    "                    'lemmatize, tdif_vec, ngrams:(1,2)',\n",
    "                    'stemming, tdif_vec, ngrams:(1,3)',\n",
    "                    'lemmatize, tdif_vec, ngrams:(1,3)',\n",
    "                    'stemming, tdif_vec, ngrams:(2,3)',\n",
    "                    'lemmatize, tdif_vec, ngrams:(2,3)']\n",
    "    labels = [ml + ' - ' + pl for ml in model_labels for pl in param_labels]\n",
    "\n",
    "    # Create a table with results from all the model runs\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df['model_configuration'] = labels\n",
    "    results_df[['mean_accuracy', 'standard_deviation']] = [[v[0], v[1]] for v in mccv.results_dict.values()]\n",
    "    results_df['sharpe_ratio'] = results_df['mean_accuracy'] / results_df['standard_deviation']\n",
    "    results_df.sort_values('mean_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation results\n",
    "\n",
    "Running the 32 model configurations through cross validation we obtain the following results:\n",
    "\n",
    "| | model_configuration |\tmean_accuracy |\tstandard_deviation | sharpe_ratio \n",
    "| :---: | :-- | :-- | :-- |:-- \n",
    "|26|SVM - stemming, tdif_vec, ngrams:(1,2)|0.80261|0.017679|45.39994\n",
    "|28|SVM - stemming, tdif_vec, ngrams:(1,3)|0.800402|0.018121|44.169086\n",
    "|24|SVM - stemming, tdif_vec, ngrams:(1,1)|0.798795|0.02067|38.645044\n",
    "|27|SVM - lemmatize, tdif_vec, ngrams:(1,2)|0.797289|0.019036|41.882422\n",
    "|29|SVM - lemmatize, tdif_vec, ngrams:(1,3)|0.796888|0.018725|42.558405\n",
    "|25|SVM - lemmatize, tdif_vec, ngrams:(1,1)|0.791667|0.017872|44.297054\n",
    "|2|MNB - stemming, count_vec, ngrams:(1,2)|0.778213|0.022113|35.192213\n",
    "|4|MNB - stemming, count_vec, ngrams:(1,3)|0.77761|0.022901|33.95591\n",
    "|3|MNB - lemmatize, count_vec, ngrams:(1,2)|0.777309|0.021255|36.570982\n",
    "|20|SVM - stemming, count_vec, ngrams:(1,3)|0.776104|0.017552|44.218379\n",
    "|5|MNB - lemmatize, count_vec, ngrams:(1,3)|0.776004|0.022181|34.984313\n",
    "|18|SVM - stemming, count_vec, ngrams:(1,2)|0.775201|0.016743|46.299987\n",
    "|10|MNB - stemming, tdif_vec, ngrams:(1,2)|0.774498|0.024231|31.963479\n",
    "|12|MNB - stemming, tdif_vec, ngrams:(1,3)|0.773193|0.022676|34.097593\n",
    "|11|MNB - lemmatize, tdif_vec, ngrams:(1,2)|0.77259|0.025614|30.162558\n",
    "|8|MNB - stemming, tdif_vec, ngrams:(1,1)|0.771787|0.023598|32.705901\n",
    "|9|MNB - lemmatize, tdif_vec, ngrams:(1,1)|0.770884|0.023805|32.383079\n",
    "|13|MNB - lemmatize, tdif_vec, ngrams:(1,3)|0.770382|0.024118|31.94284\n",
    "|1|MNB - lemmatize, count_vec, ngrams:(1,1)|0.769478|0.02098|36.676994\n",
    "|0|MNB - stemming, count_vec, ngrams:(1,1)|0.767972|0.022627|33.940625\n",
    "|21|SVM - lemmatize, count_vec, ngrams:(1,3)|0.767671|0.017052|45.02011\n",
    "|19|SVM - lemmatize, count_vec, ngrams:(1,2)|0.765663|0.016723|45.783845\n",
    "|17|SVM - lemmatize, count_vec, ngrams:(1,1)|0.755622|0.019454|38.841317\n",
    "|16|SVM - stemming, count_vec, ngrams:(1,1)|0.754418|0.020572|36.671551\n",
    "|30|SVM - stemming, tdif_vec, ngrams:(2,3)|0.744378|0.019516|38.141574\n",
    "|31|SVM - lemmatize, tdif_vec, ngrams:(2,3)|0.743775|0.020309|36.62304\n",
    "|15|MNB - lemmatize, tdif_vec, ngrams:(2,3)|0.742771|0.021729|34.184122\n",
    "|14|MNB - stemming, tdif_vec, ngrams:(2,3)|0.742771|0.025518|29.107943\n",
    "|6|MNB - stemming, count_vec, ngrams:(2,3)|0.741767|0.019033|38.972837\n",
    "|7|MNB - lemmatize, count_vec, ngrams:(2,3)|0.732731|0.022269|32.903263\n",
    "|22|SVM - stemming, count_vec, ngrams:(2,3)|0.729217|0.017586|41.464964\n",
    "|23|SVM - lemmatize, count_vec, ngrams:(2,3)|0.723896|0.017378|41.654733"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cross-validation results, we can see that models using SVM and TF-IDF vectorization generate the best results. Model configurations which exclude unigrams generate the worst results.\n",
    "\n",
    "Our best model uses SVM with TF-IDF vectorisation, stemming and both unigrams and bigrams. This model achieves cv accuracy of 80.26% and a standard deviation of 1.77%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing our baseline model with the SVM classifier\n",
    "\n",
    "Let's run cross validation for the baseline and new classifier and plot the cv density functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare MNB and SVM models using Monte Carlo Cross Validation\n",
    "run_mccv = False\n",
    "\n",
    "if run_mccv:\n",
    "    models = [MultinomialNB(),\n",
    "              LinearSVC()]\n",
    "\n",
    "    params = [{'stem':True, 'count_vectorizer':True, 'min_df':1, 'ngram_range':(1, 1)},\n",
    "              {'stem':True, 'count_vectorizer':False, 'min_df':2, 'ngram_range':(1, 2)}]\n",
    "\n",
    "    mccv = MonteCarloCV(models, number_of_runs=30)\n",
    "    mccv.train_params(x_train, y_train, feature_processing=feature_vectorisation, params=params,\n",
    "                      verbose=True, verbose_n=10)\n",
    "\n",
    "    model_labels = ['MNB', 'SVM']\n",
    "    param_labels = ['stemming, count_vec, ngrams:(1, 1)',\n",
    "                    'lemmatize, tdif_vec, ngrams:(1, 3)']\n",
    "    labels = [model_labels[i] + ' ' + param_labels[i] for i in range(len(model_labels))]\n",
    "    mccv.plot_scores(labels=labels, xlim=(0.67, 0.87))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='mccv2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the cv density functions, we can see that the MNB and SVM accuracy distributions are markedly different. The SVM distribution has a higher mean accuracy and a tighter distribution, as measured by the standard deviation. Overall the SVM looks like a better model.\n",
    "\n",
    "Now let's check performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy 1.0\n",
      "test set accuracy 0.8159\n"
     ]
    }
   ],
   "source": [
    "# Train the model and print accuracy\n",
    "x_train_lemm = stem_docs(x_train)\n",
    "x_test_lemm = stem_docs(x_test)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2))\n",
    "vectorizer.fit(x_train_lemm)\n",
    "\n",
    "x_train_vec = vectorizer.transform(x_train_lemm).toarray()\n",
    "x_test_vec = vectorizer.transform(x_test_lemm).toarray()\n",
    "    \n",
    "clf = LinearSVC()\n",
    "clf.fit(x_train_vec, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(x_train_vec)\n",
    "y_test_pred = clf.predict(x_test_vec)\n",
    "\n",
    "print_accuracy(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test set confusion matrix (proportion):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted:0</th>\n",
       "      <th>Predicted:1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual:0</th>\n",
       "      <td>0.4007</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.5054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual:1</th>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.4801</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted:0  Predicted:1   Total\n",
       "Actual:0       0.4007       0.1047  0.5054\n",
       "Actual:1       0.0794       0.4152  0.4946\n",
       "Total          0.4801       0.5199  1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print confusion matrices\n",
    "train_cm_prop = labelled_confusion_matrix(y_train, y_train_pred, prop=True) \n",
    "test_cm_prop = labelled_confusion_matrix(y_test, y_test_pred, prop=True) \n",
    "\n",
    "print('\\ntest set confusion matrix (proportion):')\n",
    "display(test_cm_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM achieves a test set accuracy of 81.59%, a slight improvement over the average cv accuracy of 80.26%.\n",
    "\n",
    "Looking at the test set confusion matrix we see that 10.47% of our predictions are false positives and 7.94% are false negatives. These represent 15% and 31% respective improvements over our baseline model.\n",
    "\n",
    "Although we have improved the classifier considerably, it is still a far way from human level performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- After trialling multiple model configurations we find that:\n",
    "    - Using an SVM and the TF-IDF vectorizer generate superior results compared to using multinomial naive Bayes and a count vectorizer\n",
    "    - The best model uses SVM with TF-IDF vectorisation, stemming and both unigrams and bigrams. \n",
    "    - This model achieves cv accuracy of 80.26%, a 4.5% improvement over the baseline model\n",
    "    - Our chosen model achieves a test set accuracy of 81.59%, which is consistent with results from cross-validation\n",
    "    - Although we have managed to improve the results of the classifier, they are still far from human level performance\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Document vectors <a id='part2.3'></a>\n",
    "\n",
    "So far we have used bag of words models to create numerical representations of the car reviews data. We transform each review into a fixed-length vector, where each element in the vector represents the number of times that a given word appears in the document, or the TF-IDF normalised value if using the TF-IDF vectorizer.\n",
    "\n",
    "Although they have served us well thus far, bag of words models have several limitations. They suffer from data sparsity and high dimensionality and they ignore the order and semantics of words. For example, 'I live to work' and 'I work to live' have identical bag of words representations, despite the meaning of each sentence being very different due to the differing word order. Additionally, words such as 'run', 'walk' and 'pizza' are equally distant, despite the fact that 'run' and 'walk' are closer semantically.\n",
    "\n",
    "#### Doc2Vec\n",
    "Building on the foundations of Word2Vec (Mitkolov et al., 2013), Doc2Vec is an unsupervised learning algorithm which generates densely populated, fixed-length feature representations from documents of varying lengths (Le and Mitkolov, 2014). \n",
    "\n",
    "The vector representations are trained to predict the surrounding words in various contexts sampled from the documents. These vector representations are learned via a shallow neural network.\n",
    "\n",
    "Doc2Vec improves on the shortcomings of bag of words models in several ways: documents can be represented in fewer dimensions, vectors are densely populated and documents with similar meanings share a similar vector space.\n",
    "\n",
    "#### Training a Doc2Vec model\n",
    "We will train a Doc2Vec model using Gensim's Doc2Vec implementation and use the following hyperparameter settings as suggested by Lau and Baldwin (2016):\n",
    "- dm: 0 (use distributed bag of words algorithm instead of distributed memory)\n",
    "- vector size: 300\n",
    "- window size: 15\n",
    "- min count: 5\n",
    "- sub-sample: 10e-5\n",
    "- epochs: 20\n",
    "- alpha: 0.025\n",
    "\n",
    "#### Sentiment prediction using Doc2Vec\n",
    "After training a Doc2Vec model, we will transform our reviews into document vectors and use a logistic regression model to predict sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orangered'> **Implementation note:**  \n",
    "A function called feature_vectorisation_d2v is passed into the MonteCarloCV train_params() method and handles the parameters and training of the Doc2Vec model.\n",
    "    \n",
    "This function ensures that the document vectors are trained only on the cv training set and then applied to the cv validation set in order to prevent any data leakage.  \n",
    "\n",
    "See car_reviews_utils.py for further details.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Warning! There are several non-deterministic components in the Doc2Vec model, therefore results in the following cells vary slightly if the cells are run again.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model using document vectors as features\n",
    "run_mccv = False\n",
    "\n",
    "if run_mccv:\n",
    "    models = [LogisticRegression(max_iter=1000)]\n",
    "\n",
    "    mccv = MonteCarloCV(models, number_of_runs=30)\n",
    "    mccv.train(x_train, y_train, feature_processing=feature_vectorisation_d2v, verbose=True, verbose_n=10)\n",
    "\n",
    "    model_labels = ['Logistic Regression']\n",
    "    mccv.plot_scores(labels=model_labels, xlim=(0.62, 0.82))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='mccv3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Doc2Vec and logistic regression model achieves a mean cv accuracy of 72.51% with a standard deviation of 2.23%. These results are poor relative to those produced by both MNB and SVM models.\n",
    "\n",
    "We have used the hyperparameter settings as suggested by Lau and Baldwin (2016), however testing of other hyperparameter combinations could improve performance. This is beyond the scope of this assignment.\n",
    "\n",
    "Additionally, Doc2Vec models have been shown to perform better when trained on very large corpuses containing millions of examples as well as pretrained word vectors (Lau and Baldwin, 2016). Our corpus is relatively small and this is reflected in the performance of the model.\n",
    "\n",
    "For completeness, let's check test set performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy 0.7837\n",
      "test set accuracy 0.7329\n"
     ]
    }
   ],
   "source": [
    "# Train the model and print accuracy\n",
    "x_train_tagged = label_sentences(x_train, 'Train')\n",
    "x_test_tagged = label_sentences(x_test, 'Test')\n",
    "\n",
    "d2v_model = Doc2Vec(dm=0, vector_size=300, window=15, min_count=5, \n",
    "                    sample=10e-5, alpha=0.025, epochs=20)\n",
    "d2v_model.build_vocab(x_train_tagged)\n",
    "d2v_model.train(x_train_tagged, total_examples=len(x_train_tagged), epochs=d2v_model.epochs)\n",
    "\n",
    "train_vectors_dbow = get_vectors(d2v_model, x_train_tagged)\n",
    "test_vectors_dbow = get_vectors(d2v_model, x_test_tagged)\n",
    "    \n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(train_vectors_dbow)\n",
    "y_test_pred = clf.predict(test_vectors_dbow)\n",
    "\n",
    "print_accuracy(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test set confusion matrix (proportion):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted:0</th>\n",
       "      <th>Predicted:1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual:0</th>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.5054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual:1</th>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.4801</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted:0  Predicted:1   Total\n",
       "Actual:0       0.3791       0.1264  0.5054\n",
       "Actual:1       0.1408       0.3538  0.4946\n",
       "Total          0.5199       0.4801  1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print confusion matrices\n",
    "test_cm_prop = labelled_confusion_matrix(y_test, y_test_pred, prop=True) \n",
    "\n",
    "print('\\ntest set confusion matrix (proportion):')\n",
    "display(test_cm_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Doc2Vec and logistic regression model only achieves an accuracy of 73.29% on the test set.\n",
    "\n",
    "Observing the test set confusion matrix, we see a 21% increase in false positives and a 77% increase in false negatives compared with our SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Summary**\n",
    "- Doc2Vec provides an alternative to the bag of words methods we have used so far and enables a more compact representation of our documents and improves on the shortcomings of bag of word models\n",
    "- We have implemented a Doc2Vec model using hyperparameters suggested by Lau and Baldwin (2016)\n",
    "- The Doc2Vec and logistic regression model achieves a mean cv accuracy of 72.51% and test set accuracy of 73.29%\n",
    "- These results are poor relative to the MNB and SVM models\n",
    "- There is scope to improve these results through further hyperparameter tuning and training on a larger corpus\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conclusions <a id='part3'></a>\n",
    "\n",
    "In this assignment we have explored several methods to predict the sentiment from our car review data. \n",
    "\n",
    "In part 1 we cleaned our data, applied stemming, transformed our data using a bag of words model and then used multinomial naive Bayes to predict sentiment.\n",
    "\n",
    "In part 2 we made efforts to improve our classifier. We have used cross-validation to generate more robust performance estimates and compare models. We have trialled the use of support vector machines, lemmatization, TF-IDF weighting and the inclusion of bigrams and trigrams. We have also touched on the use of more sophisticated representations of our data in the form of document vectors.\n",
    "\n",
    "Our best model uses a SVM with TF-IDF vectorisation, stemming and both unigrams and bigrams. This model achieves a cv accuracy of 80.26%, a 4.5% improvement over our MNB baseline model. Performance is consistent on the test set, where the SVM achieves 81.59% accuracy. Although we have managed to improve upon our original MNB classifier, the expected performance from our SVM model is still well below human performance.\n",
    "\n",
    "Results from using Doc2Vec in conjunction with logistic regression are disappointing, however these could be improved through increasing the corpus size and further hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. References <a id='part4'></a>\n",
    "\n",
    "M. F. Porter. (1980). An algorithm for suffix stripping. Program, 14(3), 130-137. Retrieved from https://tartarus.org/martin/PorterStemmer/def.txt\n",
    "\n",
    "Snowballstem. (2002). The English (Porter2) stemming algorithm. https://snowballstem.org/algorithms/english/stemmer.html\n",
    "\n",
    "Wang, S. & Manning, C. D. (2012). Baselines and bigrams: Simple, good sentiment and text classification. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics. Retrieved from https://www.aclweb.org/anthology/P12-2018.pdf\n",
    "\n",
    "Mikolov, T., Chen, K., Corrado, G. & Dean J. (2013). Efficient Estimation of Word Representations in Vector Space. Google. Retrieved from https://arxiv.org/pdf/1301.3781.pdf\n",
    "\n",
    "Le, Q. & Mikolov, T. (2014). Distributed Representations of Sentences and Documents. In Proceedings of the 31st International Conference on Machine Learning, Beijing, China. Retrieved from https://arxiv.org/pdf/1405.4053.pdf\n",
    "\n",
    "Zheng, A. (2015). Evaluating Machine Learning Models. Boston, O'Reilly Media.\n",
    "\n",
    "Lau, J. H. & Balwin, T. (2016). An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation. In Proceedings of the 1st Workshop on Representation Learning for NLP, 78–86. Retrieved from https://www.aclweb.org/anthology/W16-1609.pdf\n",
    "\n",
    "Geron, A. (2017). Hands-On Machine Learning with Scikit-Learn & TensorFlow. Boston, O'Reilly Media.\n",
    "\n",
    "Albon, C. (2018). Python Machine Learning Cookbook. Boston, O'Reilly Media.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
